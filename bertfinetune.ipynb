{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/josepsmachine/miniforge3/envs/ML/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import  Tokenized_Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Tokenized_Dataset(json_file='negacio_uab_revised_version.json', tokenizer_name='bert-base-multilingual-cased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "do train_test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "train_ratio = 0.7\n",
    "train_size = int(train_ratio * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_data, val_data = random_split(dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "batch_size = 1\n",
    "train_loader = DataLoader(train_data,batch_size)\n",
    "val_loader = DataLoader(val_data,batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import pre-trained bert multillingual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel\n",
    "bert = BertModel.from_pretrained('bert-base-multilingual-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test a sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': tensor([[ 12479,  37241,  65921,  10112,  10104,  11782,  12563,    182,  10237,\n",
       "           10350,    115,    115,    115,    115,    115,    115,    115,    115,\n",
       "             113,    115,    115,    115,    115,    115,    115,    115,    115,\n",
       "             114,  12089,    118,    190,    118,    182,  71843,    123,    120,\n",
       "             125,  10406,  10410,  10162,  12642,    119,  11052,  15603,  86153,\n",
       "           12458,    119,  10907,  10196,  24154,  11129,  63256,  10415,    177,\n",
       "           48602,  12429,  48832,  37253,  11130,  10104,  10109,  41807,  13584,\n",
       "             119,  48602,  10104,  10109,  10104,  58771,  13584,  63256,  10415,\n",
       "           12074,    119,  11417,  71560,  11669, 100527,    172,    112,  83360,\n",
       "           11231,  55391,  60304,    113,    123,    114,  12074,    119,  12428,\n",
       "           71560,  11669, 100527,    172,    112,  94614,    177,  62893,  30698,\n",
       "          101493,  12926,  10138, 107126,    177,  11639,  76454,  61804,  15880,\n",
       "             169,    180,    112,  14855,    118,  11473,  32524,  11043,  10317,\n",
       "           10125,  13829,  10104,  14249,  10245,  10575,  24540,  29322,  10107,\n",
       "             113,  10120,  63143,  15559,  28558,    117,  36979,  73099,  15559,\n",
       "           10133,    117,  55766,  63562,  10465,    114,  10549,  14931,  10104,\n",
       "           13829,  57680,  10133,    117,  36965,    183,  11572,  72327,  20213,\n",
       "             119,    118,  62304,  10795,  31119,  10220,  10671,  20125,  11911,\n",
       "             119,    118,  11600,  18487,  11520,  40230,  10425,  10104,  10164,\n",
       "           14298,    123,  27937,  12333,  10164,  10671,    119,    118,  23575,\n",
       "           11419,  22815,  67645,  23517,    117,  73290,  10341,  11284,  64764,\n",
       "           15204,    119,    118,  23072,    193,  10854,  24440,  17370,  15204,\n",
       "           10104,  47582,  65699,  10107,  10104,  10233,  22759,  11782,  11300,\n",
       "           10237,    119,  12608,  10104,  12229,  17467, 108437,  10161,  39599,\n",
       "             119,  56708,  10164,  14855,    131,    118,  11264,  37615,  29101,\n",
       "           10251,    113,  10110,  16648,  16824,    114,    127,  10147,  10240,\n",
       "             117,  10119,  10212,  52302,  99279,  10104,    125,  10147,  10240,\n",
       "             193,  10398,  10212, 101319,  99279,  10104,    122,  10147,  10240,\n",
       "             169,  10285,    130,  11008,  10164,  14298,  82432,  22866,  12847,\n",
       "           10127,  15928,  53452,  25091,    119,    118,  18283,  12597,  12920,\n",
       "           10197,  10147,  10240,    117,  15368,  10212, 101319,  99279,  10107,\n",
       "           10104,    126,  10147,  10240,    169,  10285,    130,  11008,  10104,\n",
       "           10109,  61816,    119,    118,  84314,  20324,  16818,  35304,  46912,\n",
       "           77880,  21785,  12186,  10147,  10240,  11782,  10186,  22759,    117,\n",
       "           10398,  10212, 101319,  99279,  10107,  10104,  10757,  10147,  10240,\n",
       "             169,  10285,    130,  11008,    193,  10398,  10212, 101319,  99279,\n",
       "           10107,    169,  10285,  10296,  10237,  10104,  10109,  29190,    119,\n",
       "             118,  11170,  21570,  11033,  14220,  12096,  10161,  10832,    120,\n",
       "           11176,    132,  10119,  10212, 101319,  99279,    169,  10285,  10296,\n",
       "           10237,    119,    118,  15498,  78887,  10113,  10349,  32080,  10129,\n",
       "           10186,    189,  10116,    169,  10285,    130,  11008,    119,  12608,\n",
       "           10104,    170,  18193,  10107,  12847,  10104,  11782,  56588,    113,\n",
       "           12797,  12819,    193,  11264,  10165,    169,  86153,  10107,  68247,\n",
       "           10107,  64102,  22698,  30695,    114,    118,  16856,  53750,  11249,\n",
       "             131,    170,  18193,  15928,  25285,  10343,  56588,    193,  34401,\n",
       "             131,    115,  11766,    118,  10777,    131,    116,    125,    115,\n",
       "           10777,    118,  12214,    131,    116,    127,    115,    111,    175,\n",
       "           10123,    132,  12214,    116,    129,    118,  10414,  14601,  10703,\n",
       "           46350,  10197,  10147,  10240,  62893,  13167,    117,  10110,  10125,\n",
       "           15928,  25285,  10343,    193,  34401,    119,    118,  10467,  13362,\n",
       "           22698,  11481,    123,    119,    126,  10147,  10240,    117,  10119,\n",
       "           10212, 101319,  37527,  10133,  10110,  10125,  15928,  25285,  10343,\n",
       "             119,    118, 105125,    174,  15847,  10812,    126,  10147,  10240,\n",
       "             117,  10119,  10350,  10209, 101319,  99279,  10110,  10109,  34401,\n",
       "             119,    118,  15050,  98800,  10116,  10258,  10627,  11703,    117,\n",
       "           10119,  10212, 101319,  99279,  10110,  10109,  56588,    193,  10110,\n",
       "           10109,  34401,    119,    118,  14918,  29899,  20316,  10219]]),\n",
       " 'x_ref': [('93',),\n",
       "  ('trans',),\n",
       "  ('##plant',),\n",
       "  ('##e',),\n",
       "  ('de',),\n",
       "  ('cada',),\n",
       "  ('##ver',),\n",
       "  ('n',),\n",
       "  ('##h',),\n",
       "  ('##c',),\n",
       "  ('*',),\n",
       "  ('*',),\n",
       "  ('*',),\n",
       "  ('*',),\n",
       "  ('*',),\n",
       "  ('*',),\n",
       "  ('*',),\n",
       "  ('*',),\n",
       "  ('(',),\n",
       "  ('*',),\n",
       "  ('*',),\n",
       "  ('*',),\n",
       "  ('*',),\n",
       "  ('*',),\n",
       "  ('*',),\n",
       "  ('*',),\n",
       "  ('*',),\n",
       "  (')',),\n",
       "  ('age',),\n",
       "  ('-',),\n",
       "  ('v',),\n",
       "  ('-',),\n",
       "  ('n',),\n",
       "  ('##fr',),\n",
       "  ('2',),\n",
       "  ('/',),\n",
       "  ('4',),\n",
       "  ('lo',),\n",
       "  ('##p',),\n",
       "  ('##d',),\n",
       "  ('89',),\n",
       "  ('.',),\n",
       "  ('08',),\n",
       "  ('altra',),\n",
       "  ('consulta',),\n",
       "  ('92',),\n",
       "  ('.',),\n",
       "  ('03',),\n",
       "  ('es',),\n",
       "  ('##can',),\n",
       "  ('##ner',),\n",
       "  ('ren',),\n",
       "  ('##al',),\n",
       "  ('i',),\n",
       "  ('estudi',),\n",
       "  ('radio',),\n",
       "  ('##iso',),\n",
       "  ('##top',),\n",
       "  ('##ic',),\n",
       "  ('de',),\n",
       "  ('la',),\n",
       "  ('fun',),\n",
       "  ('##cio',),\n",
       "  ('.',),\n",
       "  ('estudi',),\n",
       "  ('de',),\n",
       "  ('la',),\n",
       "  ('de',),\n",
       "  ('##pura',),\n",
       "  ('##cio',),\n",
       "  ('ren',),\n",
       "  ('##al',),\n",
       "  ('88',),\n",
       "  ('.',),\n",
       "  ('75',),\n",
       "  ('ultra',),\n",
       "  ('##so',),\n",
       "  ('diagnostic',),\n",
       "  ('d',),\n",
       "  (\"'\",),\n",
       "  ('apare',),\n",
       "  ('##ll',),\n",
       "  ('uri',),\n",
       "  ('##nari',),\n",
       "  ('(',),\n",
       "  ('2',),\n",
       "  (')',),\n",
       "  ('88',),\n",
       "  ('.',),\n",
       "  ('76',),\n",
       "  ('ultra',),\n",
       "  ('##so',),\n",
       "  ('diagnostic',),\n",
       "  ('d',),\n",
       "  (\"'\",),\n",
       "  ('abdomen',),\n",
       "  ('i',),\n",
       "  ('ret',),\n",
       "  ('##rop',),\n",
       "  ('##erit',),\n",
       "  ('##one',),\n",
       "  ('##u',),\n",
       "  ('tractament',),\n",
       "  ('i',),\n",
       "  ('re',),\n",
       "  ('##coma',),\n",
       "  ('##nac',),\n",
       "  ('##ions',),\n",
       "  ('a',),\n",
       "  ('l',),\n",
       "  (\"'\",),\n",
       "  ('alta',),\n",
       "  ('-',),\n",
       "  ('contra',),\n",
       "  ('##ind',),\n",
       "  ('##ica',),\n",
       "  ('##do',),\n",
       "  ('el',),\n",
       "  ('uso',),\n",
       "  ('de',),\n",
       "  ('anti',),\n",
       "  ('##in',),\n",
       "  ('##f',),\n",
       "  ('##lama',),\n",
       "  ('##torio',),\n",
       "  ('##s',),\n",
       "  ('(',),\n",
       "  ('di',),\n",
       "  ('##clo',),\n",
       "  ('##fen',),\n",
       "  ('##aco',),\n",
       "  (',',),\n",
       "  ('ibu',),\n",
       "  ('##pro',),\n",
       "  ('##fen',),\n",
       "  ('##o',),\n",
       "  (',',),\n",
       "  ('ena',),\n",
       "  ('##nty',),\n",
       "  ('##um',),\n",
       "  (')',),\n",
       "  ('ya',),\n",
       "  ('sea',),\n",
       "  ('de',),\n",
       "  ('uso',),\n",
       "  ('topic',),\n",
       "  ('##o',),\n",
       "  (',',),\n",
       "  ('oral',),\n",
       "  ('o',),\n",
       "  ('end',),\n",
       "  ('##oven',),\n",
       "  ('##oso',),\n",
       "  ('.',),\n",
       "  ('-',),\n",
       "  ('dieta',),\n",
       "  ('sin',),\n",
       "  ('sal',),\n",
       "  ('para',),\n",
       "  ('dia',),\n",
       "  ('##bet',),\n",
       "  ('##ico',),\n",
       "  ('.',),\n",
       "  ('-',),\n",
       "  ('ing',),\n",
       "  ('##esta',),\n",
       "  ('hi',),\n",
       "  ('##dri',),\n",
       "  ('##ca',),\n",
       "  ('de',),\n",
       "  ('al',),\n",
       "  ('menos',),\n",
       "  ('2',),\n",
       "  ('lit',),\n",
       "  ('##ros',),\n",
       "  ('al',),\n",
       "  ('dia',),\n",
       "  ('.',),\n",
       "  ('-',),\n",
       "  ('evitar',),\n",
       "  ('ex',),\n",
       "  ('##pos',),\n",
       "  ('##icion',),\n",
       "  ('solar',),\n",
       "  (',',),\n",
       "  ('aplicar',),\n",
       "  ('##se',),\n",
       "  ('pro',),\n",
       "  ('##tec',),\n",
       "  ('##cion',),\n",
       "  ('.',),\n",
       "  ('-',),\n",
       "  ('peso',),\n",
       "  ('y',),\n",
       "  ('cu',),\n",
       "  ('##anti',),\n",
       "  ('##fica',),\n",
       "  ('##cion',),\n",
       "  ('de',),\n",
       "  ('diu',),\n",
       "  ('##resi',),\n",
       "  ('##s',),\n",
       "  ('de',),\n",
       "  ('24',),\n",
       "  ('horas',),\n",
       "  ('cada',),\n",
       "  ('48',),\n",
       "  ('##h',),\n",
       "  ('.',),\n",
       "  ('control',),\n",
       "  ('de',),\n",
       "  ('pre',),\n",
       "  ('##sion',),\n",
       "  ('arteria',),\n",
       "  ('##l',),\n",
       "  ('diario',),\n",
       "  ('.',),\n",
       "  ('tratamiento',),\n",
       "  ('al',),\n",
       "  ('alta',),\n",
       "  (':',),\n",
       "  ('-',),\n",
       "  ('tra',),\n",
       "  ('##cro',),\n",
       "  ('##lim',),\n",
       "  ('##us',),\n",
       "  ('(',),\n",
       "  ('en',),\n",
       "  ('##var',),\n",
       "  ('##sus',),\n",
       "  (')',),\n",
       "  ('6',),\n",
       "  ('##m',),\n",
       "  ('##g',),\n",
       "  (',',),\n",
       "  ('un',),\n",
       "  ('com',),\n",
       "  ('##pr',),\n",
       "  ('##mido',),\n",
       "  ('de',),\n",
       "  ('4',),\n",
       "  ('##m',),\n",
       "  ('##g',),\n",
       "  ('y',),\n",
       "  ('dos',),\n",
       "  ('com',),\n",
       "  ('##pri',),\n",
       "  ('##mido',),\n",
       "  ('de',),\n",
       "  ('1',),\n",
       "  ('##m',),\n",
       "  ('##g',),\n",
       "  ('a',),\n",
       "  ('las',),\n",
       "  ('9',),\n",
       "  ('##am',),\n",
       "  ('al',),\n",
       "  ('menos',),\n",
       "  ('treinta',),\n",
       "  ('minutos',),\n",
       "  ('antes',),\n",
       "  ('del',),\n",
       "  ('desa',),\n",
       "  ('##uy',),\n",
       "  ('##uno',),\n",
       "  ('.',),\n",
       "  ('-',),\n",
       "  ('pred',),\n",
       "  ('##nis',),\n",
       "  ('##ona',),\n",
       "  ('20',),\n",
       "  ('##m',),\n",
       "  ('##g',),\n",
       "  (',',),\n",
       "  ('cuatro',),\n",
       "  ('com',),\n",
       "  ('##pri',),\n",
       "  ('##mido',),\n",
       "  ('##s',),\n",
       "  ('de',),\n",
       "  ('5',),\n",
       "  ('##m',),\n",
       "  ('##g',),\n",
       "  ('a',),\n",
       "  ('las',),\n",
       "  ('9',),\n",
       "  ('##am',),\n",
       "  ('de',),\n",
       "  ('la',),\n",
       "  ('mañana',),\n",
       "  ('.',),\n",
       "  ('-',),\n",
       "  ('mic',),\n",
       "  ('##of',),\n",
       "  ('##eno',),\n",
       "  ('##lato',),\n",
       "  ('mo',),\n",
       "  ('##fet',),\n",
       "  ('##ilo',),\n",
       "  ('1000',),\n",
       "  ('##m',),\n",
       "  ('##g',),\n",
       "  ('cada',),\n",
       "  ('12',),\n",
       "  ('horas',),\n",
       "  (',',),\n",
       "  ('dos',),\n",
       "  ('com',),\n",
       "  ('##pri',),\n",
       "  ('##mido',),\n",
       "  ('##s',),\n",
       "  ('de',),\n",
       "  ('500',),\n",
       "  ('##m',),\n",
       "  ('##g',),\n",
       "  ('a',),\n",
       "  ('las',),\n",
       "  ('9',),\n",
       "  ('##am',),\n",
       "  ('y',),\n",
       "  ('dos',),\n",
       "  ('com',),\n",
       "  ('##pri',),\n",
       "  ('##mido',),\n",
       "  ('##s',),\n",
       "  ('a',),\n",
       "  ('las',),\n",
       "  ('21',),\n",
       "  ('##h',),\n",
       "  ('de',),\n",
       "  ('la',),\n",
       "  ('noche',),\n",
       "  ('.',),\n",
       "  ('-',),\n",
       "  ('co',),\n",
       "  ('##tri',),\n",
       "  ('##mo',),\n",
       "  ('##xa',),\n",
       "  ('##zo',),\n",
       "  ('##l',),\n",
       "  ('80',),\n",
       "  ('/',),\n",
       "  ('400',),\n",
       "  (';',),\n",
       "  ('un',),\n",
       "  ('com',),\n",
       "  ('##pri',),\n",
       "  ('##mido',),\n",
       "  ('a',),\n",
       "  ('las',),\n",
       "  ('21',),\n",
       "  ('##h',),\n",
       "  ('.',),\n",
       "  ('-',),\n",
       "  ('ins',),\n",
       "  ('##ulin',),\n",
       "  ('##a',),\n",
       "  ('det',),\n",
       "  ('##emi',),\n",
       "  ('##r',),\n",
       "  ('12',),\n",
       "  ('u',),\n",
       "  ('##i',),\n",
       "  ('a',),\n",
       "  ('las',),\n",
       "  ('9',),\n",
       "  ('##am',),\n",
       "  ('.',),\n",
       "  ('control',),\n",
       "  ('de',),\n",
       "  ('b',),\n",
       "  ('##mt',),\n",
       "  ('##s',),\n",
       "  ('antes',),\n",
       "  ('de',),\n",
       "  ('cada',),\n",
       "  ('comida',),\n",
       "  ('(',),\n",
       "  ('ano',),\n",
       "  ('##tar',),\n",
       "  ('y',),\n",
       "  ('tra',),\n",
       "  ('##er',),\n",
       "  ('a',),\n",
       "  ('consulta',),\n",
       "  ('##s',),\n",
       "  ('externa',),\n",
       "  ('##s',),\n",
       "  ('nef',),\n",
       "  ('##rol',),\n",
       "  ('##ogia',),\n",
       "  (')',),\n",
       "  ('-',),\n",
       "  ('novo',),\n",
       "  ('##rap',),\n",
       "  ('##id',),\n",
       "  (':',),\n",
       "  ('b',),\n",
       "  ('##mt',),\n",
       "  ('desa',),\n",
       "  ('##yu',),\n",
       "  ('##no',),\n",
       "  ('comida',),\n",
       "  ('y',),\n",
       "  ('cena',),\n",
       "  (':',),\n",
       "  ('*',),\n",
       "  ('150',),\n",
       "  ('-',),\n",
       "  ('200',),\n",
       "  (':',),\n",
       "  ('+',),\n",
       "  ('4',),\n",
       "  ('*',),\n",
       "  ('200',),\n",
       "  ('-',),\n",
       "  ('250',),\n",
       "  (':',),\n",
       "  ('+',),\n",
       "  ('6',),\n",
       "  ('*',),\n",
       "  ('&',),\n",
       "  ('g',),\n",
       "  ('##t',),\n",
       "  (';',),\n",
       "  ('250',),\n",
       "  ('+',),\n",
       "  ('8',),\n",
       "  ('-',),\n",
       "  ('ni',),\n",
       "  ('##fe',),\n",
       "  ('##di',),\n",
       "  ('##pino',),\n",
       "  ('20',),\n",
       "  ('##m',),\n",
       "  ('##g',),\n",
       "  ('ret',),\n",
       "  ('##ard',),\n",
       "  (',',),\n",
       "  ('en',),\n",
       "  ('el',),\n",
       "  ('desa',),\n",
       "  ('##yu',),\n",
       "  ('##no',),\n",
       "  ('y',),\n",
       "  ('cena',),\n",
       "  ('.',),\n",
       "  ('-',),\n",
       "  ('bis',),\n",
       "  ('##op',),\n",
       "  ('##rol',),\n",
       "  ('##ol',),\n",
       "  ('2',),\n",
       "  ('.',),\n",
       "  ('5',),\n",
       "  ('##m',),\n",
       "  ('##g',),\n",
       "  (',',),\n",
       "  ('un',),\n",
       "  ('com',),\n",
       "  ('##pri',),\n",
       "  ('##md',),\n",
       "  ('##o',),\n",
       "  ('en',),\n",
       "  ('el',),\n",
       "  ('desa',),\n",
       "  ('##yu',),\n",
       "  ('##no',),\n",
       "  ('.',),\n",
       "  ('-',),\n",
       "  ('acido',),\n",
       "  ('f',),\n",
       "  ('##oli',),\n",
       "  ('##co',),\n",
       "  ('5',),\n",
       "  ('##m',),\n",
       "  ('##g',),\n",
       "  (',',),\n",
       "  ('un',),\n",
       "  ('##c',),\n",
       "  ('om',),\n",
       "  ('##pri',),\n",
       "  ('##mido',),\n",
       "  ('en',),\n",
       "  ('la',),\n",
       "  ('cena',),\n",
       "  ('.',),\n",
       "  ('-',),\n",
       "  ('pot',),\n",
       "  ('##ass',),\n",
       "  ('##i',),\n",
       "  ('25',),\n",
       "  ('##me',),\n",
       "  ('##q',),\n",
       "  (',',),\n",
       "  ('un',),\n",
       "  ('com',),\n",
       "  ('##pri',),\n",
       "  ('##mido',),\n",
       "  ('en',),\n",
       "  ('la',),\n",
       "  ('comida',),\n",
       "  ('y',),\n",
       "  ('en',),\n",
       "  ('la',),\n",
       "  ('cena',),\n",
       "  ('.',),\n",
       "  ('-',),\n",
       "  ('tam',),\n",
       "  ('##sul',),\n",
       "  ('##osi',),\n",
       "  ('##na',)],\n",
       " 'y': tensor([[4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "          4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "          4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "          4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "          4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "          4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "          4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "          4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "          4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "          4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "          4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "          4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "          4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "          4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "          4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "          4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "          4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "          4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "          4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "          4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "          4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "          4, 4, 4, 4, 4, 4, 4, 4]])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = next(iter(train_loader))\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = bert(sample[\"x\"])\n",
    "predictions = predictions[\"last_hidden_state\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512, 768])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = sample[\"y\"]\n",
    "tags.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll define a tagger model that has a linear layer that helps project the last hidden state into the vocab we have. We'll further have a dropout for regularisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class BERT_Tagger(nn.Module):\n",
    "    def __init__(self,\n",
    "                 bert,\n",
    "                 output_dim, \n",
    "                 dropout):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.bert = bert\n",
    "        \n",
    "        embedding_dim = bert.config.to_dict()['hidden_size']\n",
    "        \n",
    "        self.fc = nn.Linear(embedding_dim,output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, tokens):\n",
    "        \n",
    "        bert_out = self.bert(tokens)[\"last_hidden_state\"]\n",
    "        \n",
    "        predictions = self.fc(bert_out)\n",
    "        \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tagger = BERT_Tagger(bert,len(dataset.uniq_tags),0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512, 5])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = bert_tagger(sample[\"x\"])\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_accuracy(preds, y, tag_pad_idx):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "    max_preds = preds.argmax(dim = 1, keepdim = True) # get the index of the max probability\n",
    "    non_pad_elements = (y != tag_pad_idx).nonzero()\n",
    "    correct = max_preds[non_pad_elements].squeeze(1).eq(y[non_pad_elements])\n",
    "    return correct.sum() / torch.FloatTensor([y[non_pad_elements].shape[0]]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epochs, dataloader, optimizer, criterion, tag_pad_idx):    \n",
    "    model.train()\n",
    "\n",
    "    for i in range(epochs):\n",
    "        for j, batch in enumerate(dataloader):\n",
    "            tokens = batch[\"x\"].to(device)\n",
    "            tags = batch[\"y\"].to(device)\n",
    "            #look if all tags in the batch are none, if so skip\n",
    "            if torch.equal(tags, torch.tensor([[dataset.uniq_tags.index(\"NONE\")]*tags.shape[1]])) :\n",
    "                continue #skip batch\n",
    "                     \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            #text = [sent len, batch size]\n",
    "            \n",
    "            predictions = model(tokens)\n",
    "            predictions = predictions.view(-1, predictions.shape[-1]) #merge sent len and batch dimensions\n",
    "\n",
    "            tags = tags.view(-1)\n",
    "            #predictions  = [sent len * batch size, output dim]\n",
    "            #tags = [sent len * batch size]\n",
    "            \n",
    "            loss = criterion(predictions, tags)\n",
    "                    \n",
    "            acc = categorical_accuracy(predictions, tags, tag_pad_idx)\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "\n",
    "            print(f\"epoch:{i} batch:{j} loss:{loss.item()} acc:{acc.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make the criterion not count loss on \"NONE\" tag\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = dataset.uniq_tags.index(\"NONE\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "LEARNING_RATE = 5e-5 #as recomended in BERT paper\n",
    "optimizer = optim.Adam(bert_tagger.parameters(), lr = LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tagger = bert_tagger.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_pad_idx = dataset.uniq_tags.index(\"NONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 batch:3 loss:0.024001633748412132 acc:1.0\n",
      "epoch:0 batch:4 loss:0.023329535499215126 acc:1.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbert_tagger\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtag_pad_idx\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[17], line 27\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, epochs, dataloader, optimizer, criterion, tag_pad_idx)\u001b[0m\n\u001b[1;32m     23\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(predictions, tags)\n\u001b[1;32m     25\u001b[0m acc \u001b[38;5;241m=\u001b[39m categorical_accuracy(predictions, tags, tag_pad_idx)\n\u001b[0;32m---> 27\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m batch:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mj\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m loss:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m acc:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(bert_tagger,100,train_loader,optimizer,criterion,tag_pad_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the model qualititavely:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from colorama import Fore, Back, Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model,dataloader,n_batches,tag_pad_idx):\n",
    "    loader = iter(dataloader)\n",
    "\n",
    "    colors = [Fore.BLUE,Fore.RED,Fore.GREEN,Fore.CYAN,Fore.WHITE]\n",
    "    reference_tag_txt = [colors[i]+dataset.uniq_tags[i] for i in range(len(dataset.uniq_tags))]\n",
    "    reference_tag_txt = \" \".join(reference_tag_txt)\n",
    "    \n",
    "    txt = \"\"\n",
    "    txt_pred = \"\"\n",
    "    for i in range(n_batches):\n",
    "        batch = next(loader)\n",
    "        tokens = batch[\"x\"].to(device)\n",
    "        tags = batch[\"y\"].to(device)\n",
    "        tokens_txt = batch[\"x_ref\"]\n",
    "        predictions = model(tokens)\n",
    "        predictions = predictions.view(-1, predictions.shape[-1]) #merge sent len and batch dimensions\n",
    "        predictions = torch.argmax(predictions,axis=1).numpy()\n",
    "        print(predictions.shape)\n",
    "        tags = tags.view(-1)\n",
    "        \n",
    "        for tok,tag,pred in zip(tokens_txt,tags,predictions):\n",
    "            if tok[0][0] == \"#\":\n",
    "                txt += colors[tag]+str(tok[0]).replace(\"#\",\"\")\n",
    "                txt_pred += colors[pred]+str(tok[0]).replace(\"#\",\"\")\n",
    "\n",
    "            else:\n",
    "                txt += \" \" + colors[tag]+str(tok[0]).replace(\"#\",\"\")\n",
    "                txt_pred += \" \" + colors[pred]+str(tok[0]).replace(\"#\",\"\")\n",
    "\n",
    "        print(reference_tag_txt)\n",
    "        print(Fore.WHITE+\"-------------------True-------------------\")\n",
    "        print(txt)\n",
    "        print(Fore.WHITE+\"-------------------True-------------------\")\n",
    "        print(Fore.WHITE+\"-------------------Pred-------------------\")\n",
    "        print(txt_pred)\n",
    "        print(Fore.WHITE+\"-------------------Pred-------------------\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512,)\n",
      "\u001b[34mUNC \u001b[31mNEG \u001b[32mNSCO \u001b[36mUSCO \u001b[37mNONE\n",
      "\u001b[37m-------------------True-------------------\n",
      " \u001b[37mesti\u001b[37mmula\u001b[37mcion \u001b[37mo\u001b[37mx\u001b[37mcito\u001b[37mcini\u001b[37mca \u001b[37m. \u001b[37mse \u001b[37mins\u001b[37mtau\u001b[37mra \u001b[37mane\u001b[37mstes\u001b[37mia \u001b[37mper\u001b[37midu\u001b[37mral \u001b[37m. \u001b[37mse \u001b[37mrealiza \u001b[37mprofil\u001b[37max\u001b[37mis \u001b[37manti\u001b[37mbio\u001b[37mtica \u001b[37mcon \u001b[37mpen\u001b[37mile\u001b[37mvel \u001b[37m5\u001b[37mm \u001b[37mu\u001b[37mi \u001b[37mdurante \u001b[37mam\u001b[37mnio\u001b[37mrre\u001b[37mxis \u001b[37m+ \u001b[37m2 \u001b[37m, \u001b[37m5 \u001b[37mm \u001b[37mu\u001b[37mi \u001b[37m/ \u001b[37m4\u001b[37mh \u001b[37mhasta \u001b[37mel \u001b[37mex\u001b[37mpuls\u001b[37mivo \u001b[37mpor \u001b[37msg\u001b[37mb \u001b[37mdes\u001b[37mcono\u001b[37mcido \u001b[37men \u001b[37mrpm \u001b[37mpret\u001b[37merm\u001b[37mino \u001b[37m. \u001b[37mpro\u001b[37mgres\u001b[37mion \u001b[37mad\u001b[37mecu\u001b[37mada \u001b[37mde \u001b[37mla \u001b[37mdil\u001b[37mata\u001b[37mcion \u001b[37mhasta \u001b[37mllegar \u001b[37ma \u001b[37mdil\u001b[37mata\u001b[37mcion \u001b[37mcompleta \u001b[37m. \u001b[37mel \u001b[37mdia \u001b[37m22 \u001b[37m/ \u001b[37m10 \u001b[37m/ \u001b[37m18 \u001b[37ma \u001b[37mlas \u001b[37m14 \u001b[37m: \u001b[37m15 \u001b[37mhoras \u001b[37m, \u001b[37mse \u001b[37masi\u001b[37mste \u001b[37mparte \u001b[37meut\u001b[37moci\u001b[37mco \u001b[37m, \u001b[37mobteniendo\u001b[37mse \u001b[37mre\u001b[37mcie\u001b[37mn \u001b[37mnacido \u001b[37mmujer \u001b[37m. \u001b[37mapa\u001b[37mgar \u001b[37m9 \u001b[37m/ \u001b[37m10 \u001b[37m. \u001b[37mpeso \u001b[37m243\u001b[37m0\u001b[37mg \u001b[37m. \u001b[37mph \u001b[37m7 \u001b[37m. \u001b[37m18 \u001b[37m/ \u001b[37m- \u001b[37m. \u001b[37mse \u001b[37mad\u001b[37mmini\u001b[37mstra \u001b[37mprofil\u001b[37max\u001b[37mis \u001b[37mo\u001b[37mcular \u001b[37mcon \u001b[37meri\u001b[37mtro\u001b[37mmic\u001b[37mina \u001b[37my \u001b[37mvitamina \u001b[37mk \u001b[37m. \u001b[37mal\u001b[37mum\u001b[37mbra\u001b[37mmiento \u001b[37mdirigido \u001b[37m. \u001b[37mplace\u001b[37mnta \u001b[37maparentemente \u001b[37mintegra \u001b[37m. \u001b[37mse \u001b[37mrev\u001b[37misa \u001b[37mcanal \u001b[37mbland\u001b[37mo \u001b[37mdel \u001b[37mparto \u001b[37m, \u001b[37mobjet\u001b[37miva\u001b[37mndose \u001b[37mem\u001b[37mdl \u001b[37my \u001b[37mdes\u001b[37mgar\u001b[37mro \u001b[37mpare\u001b[37md \u001b[37mva\u001b[37mginal \u001b[37mderecha \u001b[37mii \u001b[37m. \u001b[37mg\u001b[37msr\u001b[37mh \u001b[37m: \u001b[37m0 \u001b[37m- \u001b[37mru\u001b[37mbe\u001b[37mola \u001b[37min\u001b[37mmune \u001b[37m. \u001b[37mlac\u001b[37mtancia \u001b[37mmaterna \u001b[37m. \u001b[37mex\u001b[37mplo\u001b[37mrac\u001b[37mion \u001b[37mfisica \u001b[37mal \u001b[37malta \u001b[37mn\u001b[37mh\u001b[37mc \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m( \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m) \u001b[37mami \u001b[37m- \u001b[37mv \u001b[37m- \u001b[37mob\u001b[37ms \u001b[37m2 \u001b[37m/ \u001b[37m3 \u001b[37mlo\u001b[37mp\u001b[37md \u001b[37mdada \u001b[37mla \u001b[37mbuena \u001b[37mevo\u001b[37mlu\u001b[37mcion \u001b[37mdurante \u001b[37mel \u001b[37mpu\u001b[37mer\u001b[37mperi\u001b[37mo \u001b[37mse \u001b[37mdecide \u001b[37malta \u001b[37ma \u001b[37mdomi\u001b[37mcilio \u001b[37men \u001b[37mel \u001b[37mdia \u001b[37mde \u001b[37mhoy \u001b[37m. \u001b[37men \u001b[37mel \u001b[37mmomento \u001b[37mdel \u001b[37malta \u001b[37mla \u001b[37mpaciente \u001b[37mse \u001b[37mencuentra \u001b[37mcon \u001b[37mbuen \u001b[37mestado \u001b[37mgeneral \u001b[37m, \u001b[37mapi\u001b[37mreti\u001b[37mca \u001b[37m, \u001b[37mnor\u001b[37mmot\u001b[37mensa \u001b[37my \u001b[37mno \u001b[37mta\u001b[37mqui\u001b[37mcard\u001b[37mica \u001b[37m. \u001b[37mute\u001b[37mro \u001b[37mbien \u001b[37mcontra\u001b[37mido \u001b[37m, \u001b[37mcon \u001b[37mperd\u001b[37midas \u001b[37mva\u001b[37mginal\u001b[37mes \u001b[37mes\u001b[37mcasa\u001b[37ms \u001b[37m. \u001b[37mrealiza \u001b[37mlac\u001b[37mtancia \u001b[37mmaterna \u001b[37m. \u001b[37mori\u001b[37menta\u001b[37mcio \u001b[37mdiagnostic\u001b[37ma \u001b[37mtrabajo \u001b[37mde \u001b[37mparto \u001b[37mparto \u001b[37meut\u001b[37moci\u001b[37mco \u001b[37mepi\u001b[37msio\u001b[37mtomia \u001b[37mml\u001b[37md \u001b[37m+ \u001b[37mdes\u001b[37mgar\u001b[37mro \u001b[37mde \u001b[37m2º \u001b[37mgrado \u001b[37mpu\u001b[37mer\u001b[37mperi\u001b[37mo \u001b[37mpro\u001b[37mced\u001b[37miments \u001b[37masistencia \u001b[37mal \u001b[37mtrabajo \u001b[37mde \u001b[37mparto \u001b[37m( \u001b[37mven\u001b[37moc\u001b[37mlisi\u001b[37ms \u001b[37m, \u001b[37mcontrol \u001b[37mde \u001b[37mconstantes \u001b[37m, \u001b[37mns\u001b[37mt \u001b[37m, \u001b[37mane\u001b[37mstes\u001b[37mia \u001b[37mepi\u001b[37mdura\u001b[37ml \u001b[37m) \u001b[37m. \u001b[37masistencia \u001b[37mal \u001b[37mparto \u001b[37mrevision \u001b[37mdel \u001b[37mcanal \u001b[37mbland\u001b[37mo \u001b[37mdel \u001b[37mparto \u001b[37msut\u001b[37mura \u001b[37mde \u001b[37mepi\u001b[37msio\u001b[37mtomia \u001b[37my \u001b[37mdes\u001b[37mgar\u001b[37mro \u001b[37manal\u001b[37mgesi\u001b[37ma \u001b[37my \u001b[37mane\u001b[37mstes\u001b[37mia \u001b[37mepi\u001b[37mdura\u001b[37ml \u001b[37msue\u001b[37mrot\u001b[37mera\u001b[37mpia \u001b[37manal\u001b[37miti\u001b[37mcas \u001b[37mg\u001b[37msr\u001b[37mh \u001b[37mtractament \u001b[37mi \u001b[37mre\u001b[37mcoma\u001b[37mnac\u001b[37mions \u001b[37ma \u001b[37ml \u001b[37m' \u001b[37malta \u001b[37mhierro \u001b[37m1 \u001b[37mcom\u001b[37mpri\u001b[37mmido \u001b[37mcada \u001b[37m24\u001b[37mh \u001b[37men \u001b[37may\u001b[37munas \u001b[37m( \u001b[37ming\u001b[37merir \u001b[37mcon \u001b[37mzum\u001b[37mo \u001b[37mde \u001b[37mnar\u001b[37manja \u001b[37mu \u001b[37motro \u001b[37malimento \u001b[37macido \u001b[37m) \u001b[37m. \u001b[37macido \u001b[37mf\u001b[37moli\u001b[37mco \u001b[37m1 \u001b[37mcom\u001b[37mpri\u001b[37mmido \u001b[37mcada \u001b[37m24\u001b[37mh \u001b[37mal \u001b[37mmedio \u001b[37mdia \u001b[37mmientras \u001b[37mdure \u001b[37mlac\u001b[37mtancia \u001b[37m. \u001b[37msi \u001b[37mpresenta \u001b[37mdolor \u001b[37mpuede \u001b[37mtomar \u001b[37mpara\u001b[37mcet\u001b[37mamo\u001b[37ml \u001b[37m1\u001b[37mcom\u001b[37mpri\u001b[37mmido \u001b[37m/ \u001b[37m8\u001b[37mh \u001b[37m. \u001b[37mcontrol \u001b[37mcontrol \u001b[37mde \u001b[37msu \u001b[37mpat\u001b[37mologia \u001b[37mde \u001b[37mbase \u001b[37m( \u001b[37mas\u001b[37mma \u001b[37m) \u001b[37msegun \u001b[37mcontrole\u001b[37ms \u001b[37mhabitual\u001b[37mes \u001b[37msi \u001b[37mpresenta \u001b[37mgr\u001b[37miet\u001b[37mas \u001b[37men \u001b[37mpez\u001b[37mones\n",
      "\u001b[37m-------------------True-------------------\n",
      "\u001b[37m-------------------Pred-------------------\n",
      " \u001b[31mesti\u001b[31mmula\u001b[31mcion \u001b[31mo\u001b[31mx\u001b[31mcito\u001b[31mcini\u001b[31mca \u001b[31m. \u001b[31mse \u001b[31mins\u001b[31mtau\u001b[31mra \u001b[31mane\u001b[31mstes\u001b[31mia \u001b[31mper\u001b[31midu\u001b[31mral \u001b[31m. \u001b[31mse \u001b[31mrealiza \u001b[31mprofil\u001b[31max\u001b[31mis \u001b[31manti\u001b[31mbio\u001b[31mtica \u001b[31mcon \u001b[31mpen\u001b[31mile\u001b[31mvel \u001b[31m5\u001b[31mm \u001b[31mu\u001b[31mi \u001b[31mdurante \u001b[31mam\u001b[31mnio\u001b[31mrre\u001b[31mxis \u001b[31m+ \u001b[31m2 \u001b[31m, \u001b[31m5 \u001b[31mm \u001b[31mu\u001b[31mi \u001b[31m/ \u001b[31m4\u001b[31mh \u001b[31mhasta \u001b[31mel \u001b[31mex\u001b[31mpuls\u001b[31mivo \u001b[31mpor \u001b[31msg\u001b[31mb \u001b[31mdes\u001b[31mcono\u001b[31mcido \u001b[31men \u001b[31mrpm \u001b[31mpret\u001b[31merm\u001b[31mino \u001b[31m. \u001b[31mpro\u001b[31mgres\u001b[31mion \u001b[31mad\u001b[31mecu\u001b[31mada \u001b[31mde \u001b[31mla \u001b[31mdil\u001b[31mata\u001b[31mcion \u001b[31mhasta \u001b[31mllegar \u001b[31ma \u001b[31mdil\u001b[31mata\u001b[31mcion \u001b[31mcompleta \u001b[31m. \u001b[31mel \u001b[31mdia \u001b[31m22 \u001b[31m/ \u001b[31m10 \u001b[31m/ \u001b[31m18 \u001b[31ma \u001b[31mlas \u001b[31m14 \u001b[31m: \u001b[31m15 \u001b[31mhoras \u001b[31m, \u001b[31mse \u001b[31masi\u001b[31mste \u001b[31mparte \u001b[31meut\u001b[31moci\u001b[31mco \u001b[31m, \u001b[31mobteniendo\u001b[31mse \u001b[31mre\u001b[31mcie\u001b[31mn \u001b[31mnacido \u001b[31mmujer \u001b[31m. \u001b[31mapa\u001b[31mgar \u001b[31m9 \u001b[31m/ \u001b[31m10 \u001b[31m. \u001b[31mpeso \u001b[31m243\u001b[31m0\u001b[31mg \u001b[31m. \u001b[31mph \u001b[31m7 \u001b[31m. \u001b[31m18 \u001b[31m/ \u001b[31m- \u001b[31m. \u001b[31mse \u001b[31mad\u001b[31mmini\u001b[31mstra \u001b[31mprofil\u001b[31max\u001b[31mis \u001b[31mo\u001b[31mcular \u001b[31mcon \u001b[31meri\u001b[31mtro\u001b[31mmic\u001b[31mina \u001b[31my \u001b[31mvitamina \u001b[31mk \u001b[31m. \u001b[31mal\u001b[31mum\u001b[31mbra\u001b[31mmiento \u001b[31mdirigido \u001b[31m. \u001b[31mplace\u001b[31mnta \u001b[31maparentemente \u001b[31mintegra \u001b[31m. \u001b[31mse \u001b[31mrev\u001b[31misa \u001b[31mcanal \u001b[31mbland\u001b[31mo \u001b[31mdel \u001b[31mparto \u001b[31m, \u001b[31mobjet\u001b[31miva\u001b[31mndose \u001b[31mem\u001b[31mdl \u001b[31my \u001b[31mdes\u001b[31mgar\u001b[31mro \u001b[31mpare\u001b[31md \u001b[31mva\u001b[31mginal \u001b[31mderecha \u001b[31mii \u001b[31m. \u001b[31mg\u001b[31msr\u001b[31mh \u001b[31m: \u001b[31m0 \u001b[31m- \u001b[31mru\u001b[31mbe\u001b[31mola \u001b[31min\u001b[31mmune \u001b[31m. \u001b[31mlac\u001b[31mtancia \u001b[31mmaterna \u001b[31m. \u001b[31mex\u001b[31mplo\u001b[31mrac\u001b[31mion \u001b[31mfisica \u001b[31mal \u001b[31malta \u001b[31mn\u001b[31mh\u001b[31mc \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m( \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m) \u001b[31mami \u001b[31m- \u001b[31mv \u001b[31m- \u001b[31mob\u001b[31ms \u001b[31m2 \u001b[31m/ \u001b[31m3 \u001b[31mlo\u001b[31mp\u001b[31md \u001b[31mdada \u001b[31mla \u001b[31mbuena \u001b[31mevo\u001b[31mlu\u001b[31mcion \u001b[31mdurante \u001b[31mel \u001b[31mpu\u001b[31mer\u001b[31mperi\u001b[31mo \u001b[31mse \u001b[31mdecide \u001b[31malta \u001b[31ma \u001b[31mdomi\u001b[31mcilio \u001b[31men \u001b[31mel \u001b[31mdia \u001b[31mde \u001b[31mhoy \u001b[31m. \u001b[31men \u001b[31mel \u001b[31mmomento \u001b[31mdel \u001b[31malta \u001b[31mla \u001b[31mpaciente \u001b[31mse \u001b[31mencuentra \u001b[31mcon \u001b[31mbuen \u001b[31mestado \u001b[31mgeneral \u001b[31m, \u001b[31mapi\u001b[31mreti\u001b[31mca \u001b[31m, \u001b[31mnor\u001b[31mmot\u001b[31mensa \u001b[31my \u001b[31mno \u001b[31mta\u001b[31mqui\u001b[31mcard\u001b[31mica \u001b[31m. \u001b[31mute\u001b[31mro \u001b[31mbien \u001b[31mcontra\u001b[31mido \u001b[31m, \u001b[31mcon \u001b[31mperd\u001b[31midas \u001b[31mva\u001b[31mginal\u001b[31mes \u001b[31mes\u001b[31mcasa\u001b[31ms \u001b[31m. \u001b[31mrealiza \u001b[31mlac\u001b[31mtancia \u001b[31mmaterna \u001b[31m. \u001b[31mori\u001b[31menta\u001b[31mcio \u001b[31mdiagnostic\u001b[31ma \u001b[31mtrabajo \u001b[31mde \u001b[31mparto \u001b[31mparto \u001b[31meut\u001b[31moci\u001b[31mco \u001b[31mepi\u001b[31msio\u001b[31mtomia \u001b[31mml\u001b[31md \u001b[31m+ \u001b[31mdes\u001b[31mgar\u001b[31mro \u001b[31mde \u001b[31m2º \u001b[31mgrado \u001b[31mpu\u001b[31mer\u001b[31mperi\u001b[31mo \u001b[31mpro\u001b[31mced\u001b[31miments \u001b[31masistencia \u001b[31mal \u001b[31mtrabajo \u001b[31mde \u001b[31mparto \u001b[31m( \u001b[31mven\u001b[31moc\u001b[31mlisi\u001b[31ms \u001b[31m, \u001b[31mcontrol \u001b[31mde \u001b[31mconstantes \u001b[31m, \u001b[31mns\u001b[31mt \u001b[31m, \u001b[31mane\u001b[31mstes\u001b[31mia \u001b[31mepi\u001b[31mdura\u001b[31ml \u001b[31m) \u001b[31m. \u001b[31masistencia \u001b[31mal \u001b[31mparto \u001b[31mrevision \u001b[31mdel \u001b[31mcanal \u001b[31mbland\u001b[31mo \u001b[31mdel \u001b[31mparto \u001b[31msut\u001b[31mura \u001b[31mde \u001b[31mepi\u001b[31msio\u001b[31mtomia \u001b[31my \u001b[31mdes\u001b[31mgar\u001b[31mro \u001b[31manal\u001b[31mgesi\u001b[31ma \u001b[31my \u001b[31mane\u001b[31mstes\u001b[31mia \u001b[31mepi\u001b[31mdura\u001b[31ml \u001b[31msue\u001b[31mrot\u001b[31mera\u001b[31mpia \u001b[31manal\u001b[31miti\u001b[31mcas \u001b[31mg\u001b[31msr\u001b[31mh \u001b[31mtractament \u001b[31mi \u001b[31mre\u001b[31mcoma\u001b[31mnac\u001b[31mions \u001b[31ma \u001b[31ml \u001b[31m' \u001b[31malta \u001b[31mhierro \u001b[31m1 \u001b[31mcom\u001b[31mpri\u001b[31mmido \u001b[31mcada \u001b[31m24\u001b[31mh \u001b[31men \u001b[31may\u001b[31munas \u001b[31m( \u001b[31ming\u001b[31merir \u001b[31mcon \u001b[31mzum\u001b[31mo \u001b[31mde \u001b[31mnar\u001b[31manja \u001b[31mu \u001b[31motro \u001b[31malimento \u001b[31macido \u001b[31m) \u001b[31m. \u001b[31macido \u001b[31mf\u001b[31moli\u001b[31mco \u001b[31m1 \u001b[31mcom\u001b[31mpri\u001b[31mmido \u001b[31mcada \u001b[31m24\u001b[31mh \u001b[31mal \u001b[31mmedio \u001b[31mdia \u001b[31mmientras \u001b[31mdure \u001b[31mlac\u001b[31mtancia \u001b[31m. \u001b[31msi \u001b[31mpresenta \u001b[31mdolor \u001b[31mpuede \u001b[31mtomar \u001b[31mpara\u001b[31mcet\u001b[31mamo\u001b[31ml \u001b[31m1\u001b[31mcom\u001b[31mpri\u001b[31mmido \u001b[31m/ \u001b[31m8\u001b[31mh \u001b[31m. \u001b[31mcontrol \u001b[31mcontrol \u001b[31mde \u001b[31msu \u001b[31mpat\u001b[31mologia \u001b[31mde \u001b[31mbase \u001b[31m( \u001b[31mas\u001b[31mma \u001b[31m) \u001b[31msegun \u001b[31mcontrole\u001b[31ms \u001b[31mhabitual\u001b[31mes \u001b[31msi \u001b[31mpresenta \u001b[31mgr\u001b[31miet\u001b[31mas \u001b[31men \u001b[31mpez\u001b[31mones\n",
      "\u001b[37m-------------------Pred-------------------\n",
      "(512,)\n",
      "\u001b[34mUNC \u001b[31mNEG \u001b[32mNSCO \u001b[36mUSCO \u001b[37mNONE\n",
      "\u001b[37m-------------------True-------------------\n",
      " \u001b[37mesti\u001b[37mmula\u001b[37mcion \u001b[37mo\u001b[37mx\u001b[37mcito\u001b[37mcini\u001b[37mca \u001b[37m. \u001b[37mse \u001b[37mins\u001b[37mtau\u001b[37mra \u001b[37mane\u001b[37mstes\u001b[37mia \u001b[37mper\u001b[37midu\u001b[37mral \u001b[37m. \u001b[37mse \u001b[37mrealiza \u001b[37mprofil\u001b[37max\u001b[37mis \u001b[37manti\u001b[37mbio\u001b[37mtica \u001b[37mcon \u001b[37mpen\u001b[37mile\u001b[37mvel \u001b[37m5\u001b[37mm \u001b[37mu\u001b[37mi \u001b[37mdurante \u001b[37mam\u001b[37mnio\u001b[37mrre\u001b[37mxis \u001b[37m+ \u001b[37m2 \u001b[37m, \u001b[37m5 \u001b[37mm \u001b[37mu\u001b[37mi \u001b[37m/ \u001b[37m4\u001b[37mh \u001b[37mhasta \u001b[37mel \u001b[37mex\u001b[37mpuls\u001b[37mivo \u001b[37mpor \u001b[37msg\u001b[37mb \u001b[37mdes\u001b[37mcono\u001b[37mcido \u001b[37men \u001b[37mrpm \u001b[37mpret\u001b[37merm\u001b[37mino \u001b[37m. \u001b[37mpro\u001b[37mgres\u001b[37mion \u001b[37mad\u001b[37mecu\u001b[37mada \u001b[37mde \u001b[37mla \u001b[37mdil\u001b[37mata\u001b[37mcion \u001b[37mhasta \u001b[37mllegar \u001b[37ma \u001b[37mdil\u001b[37mata\u001b[37mcion \u001b[37mcompleta \u001b[37m. \u001b[37mel \u001b[37mdia \u001b[37m22 \u001b[37m/ \u001b[37m10 \u001b[37m/ \u001b[37m18 \u001b[37ma \u001b[37mlas \u001b[37m14 \u001b[37m: \u001b[37m15 \u001b[37mhoras \u001b[37m, \u001b[37mse \u001b[37masi\u001b[37mste \u001b[37mparte \u001b[37meut\u001b[37moci\u001b[37mco \u001b[37m, \u001b[37mobteniendo\u001b[37mse \u001b[37mre\u001b[37mcie\u001b[37mn \u001b[37mnacido \u001b[37mmujer \u001b[37m. \u001b[37mapa\u001b[37mgar \u001b[37m9 \u001b[37m/ \u001b[37m10 \u001b[37m. \u001b[37mpeso \u001b[37m243\u001b[37m0\u001b[37mg \u001b[37m. \u001b[37mph \u001b[37m7 \u001b[37m. \u001b[37m18 \u001b[37m/ \u001b[37m- \u001b[37m. \u001b[37mse \u001b[37mad\u001b[37mmini\u001b[37mstra \u001b[37mprofil\u001b[37max\u001b[37mis \u001b[37mo\u001b[37mcular \u001b[37mcon \u001b[37meri\u001b[37mtro\u001b[37mmic\u001b[37mina \u001b[37my \u001b[37mvitamina \u001b[37mk \u001b[37m. \u001b[37mal\u001b[37mum\u001b[37mbra\u001b[37mmiento \u001b[37mdirigido \u001b[37m. \u001b[37mplace\u001b[37mnta \u001b[37maparentemente \u001b[37mintegra \u001b[37m. \u001b[37mse \u001b[37mrev\u001b[37misa \u001b[37mcanal \u001b[37mbland\u001b[37mo \u001b[37mdel \u001b[37mparto \u001b[37m, \u001b[37mobjet\u001b[37miva\u001b[37mndose \u001b[37mem\u001b[37mdl \u001b[37my \u001b[37mdes\u001b[37mgar\u001b[37mro \u001b[37mpare\u001b[37md \u001b[37mva\u001b[37mginal \u001b[37mderecha \u001b[37mii \u001b[37m. \u001b[37mg\u001b[37msr\u001b[37mh \u001b[37m: \u001b[37m0 \u001b[37m- \u001b[37mru\u001b[37mbe\u001b[37mola \u001b[37min\u001b[37mmune \u001b[37m. \u001b[37mlac\u001b[37mtancia \u001b[37mmaterna \u001b[37m. \u001b[37mex\u001b[37mplo\u001b[37mrac\u001b[37mion \u001b[37mfisica \u001b[37mal \u001b[37malta \u001b[37mn\u001b[37mh\u001b[37mc \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m( \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m) \u001b[37mami \u001b[37m- \u001b[37mv \u001b[37m- \u001b[37mob\u001b[37ms \u001b[37m2 \u001b[37m/ \u001b[37m3 \u001b[37mlo\u001b[37mp\u001b[37md \u001b[37mdada \u001b[37mla \u001b[37mbuena \u001b[37mevo\u001b[37mlu\u001b[37mcion \u001b[37mdurante \u001b[37mel \u001b[37mpu\u001b[37mer\u001b[37mperi\u001b[37mo \u001b[37mse \u001b[37mdecide \u001b[37malta \u001b[37ma \u001b[37mdomi\u001b[37mcilio \u001b[37men \u001b[37mel \u001b[37mdia \u001b[37mde \u001b[37mhoy \u001b[37m. \u001b[37men \u001b[37mel \u001b[37mmomento \u001b[37mdel \u001b[37malta \u001b[37mla \u001b[37mpaciente \u001b[37mse \u001b[37mencuentra \u001b[37mcon \u001b[37mbuen \u001b[37mestado \u001b[37mgeneral \u001b[37m, \u001b[37mapi\u001b[37mreti\u001b[37mca \u001b[37m, \u001b[37mnor\u001b[37mmot\u001b[37mensa \u001b[37my \u001b[37mno \u001b[37mta\u001b[37mqui\u001b[37mcard\u001b[37mica \u001b[37m. \u001b[37mute\u001b[37mro \u001b[37mbien \u001b[37mcontra\u001b[37mido \u001b[37m, \u001b[37mcon \u001b[37mperd\u001b[37midas \u001b[37mva\u001b[37mginal\u001b[37mes \u001b[37mes\u001b[37mcasa\u001b[37ms \u001b[37m. \u001b[37mrealiza \u001b[37mlac\u001b[37mtancia \u001b[37mmaterna \u001b[37m. \u001b[37mori\u001b[37menta\u001b[37mcio \u001b[37mdiagnostic\u001b[37ma \u001b[37mtrabajo \u001b[37mde \u001b[37mparto \u001b[37mparto \u001b[37meut\u001b[37moci\u001b[37mco \u001b[37mepi\u001b[37msio\u001b[37mtomia \u001b[37mml\u001b[37md \u001b[37m+ \u001b[37mdes\u001b[37mgar\u001b[37mro \u001b[37mde \u001b[37m2º \u001b[37mgrado \u001b[37mpu\u001b[37mer\u001b[37mperi\u001b[37mo \u001b[37mpro\u001b[37mced\u001b[37miments \u001b[37masistencia \u001b[37mal \u001b[37mtrabajo \u001b[37mde \u001b[37mparto \u001b[37m( \u001b[37mven\u001b[37moc\u001b[37mlisi\u001b[37ms \u001b[37m, \u001b[37mcontrol \u001b[37mde \u001b[37mconstantes \u001b[37m, \u001b[37mns\u001b[37mt \u001b[37m, \u001b[37mane\u001b[37mstes\u001b[37mia \u001b[37mepi\u001b[37mdura\u001b[37ml \u001b[37m) \u001b[37m. \u001b[37masistencia \u001b[37mal \u001b[37mparto \u001b[37mrevision \u001b[37mdel \u001b[37mcanal \u001b[37mbland\u001b[37mo \u001b[37mdel \u001b[37mparto \u001b[37msut\u001b[37mura \u001b[37mde \u001b[37mepi\u001b[37msio\u001b[37mtomia \u001b[37my \u001b[37mdes\u001b[37mgar\u001b[37mro \u001b[37manal\u001b[37mgesi\u001b[37ma \u001b[37my \u001b[37mane\u001b[37mstes\u001b[37mia \u001b[37mepi\u001b[37mdura\u001b[37ml \u001b[37msue\u001b[37mrot\u001b[37mera\u001b[37mpia \u001b[37manal\u001b[37miti\u001b[37mcas \u001b[37mg\u001b[37msr\u001b[37mh \u001b[37mtractament \u001b[37mi \u001b[37mre\u001b[37mcoma\u001b[37mnac\u001b[37mions \u001b[37ma \u001b[37ml \u001b[37m' \u001b[37malta \u001b[37mhierro \u001b[37m1 \u001b[37mcom\u001b[37mpri\u001b[37mmido \u001b[37mcada \u001b[37m24\u001b[37mh \u001b[37men \u001b[37may\u001b[37munas \u001b[37m( \u001b[37ming\u001b[37merir \u001b[37mcon \u001b[37mzum\u001b[37mo \u001b[37mde \u001b[37mnar\u001b[37manja \u001b[37mu \u001b[37motro \u001b[37malimento \u001b[37macido \u001b[37m) \u001b[37m. \u001b[37macido \u001b[37mf\u001b[37moli\u001b[37mco \u001b[37m1 \u001b[37mcom\u001b[37mpri\u001b[37mmido \u001b[37mcada \u001b[37m24\u001b[37mh \u001b[37mal \u001b[37mmedio \u001b[37mdia \u001b[37mmientras \u001b[37mdure \u001b[37mlac\u001b[37mtancia \u001b[37m. \u001b[37msi \u001b[37mpresenta \u001b[37mdolor \u001b[37mpuede \u001b[37mtomar \u001b[37mpara\u001b[37mcet\u001b[37mamo\u001b[37ml \u001b[37m1\u001b[37mcom\u001b[37mpri\u001b[37mmido \u001b[37m/ \u001b[37m8\u001b[37mh \u001b[37m. \u001b[37mcontrol \u001b[37mcontrol \u001b[37mde \u001b[37msu \u001b[37mpat\u001b[37mologia \u001b[37mde \u001b[37mbase \u001b[37m( \u001b[37mas\u001b[37mma \u001b[37m) \u001b[37msegun \u001b[37mcontrole\u001b[37ms \u001b[37mhabitual\u001b[37mes \u001b[37msi \u001b[37mpresenta \u001b[37mgr\u001b[37miet\u001b[37mas \u001b[37men \u001b[37mpez\u001b[37mones \u001b[37m* \u001b[37m* \u001b[37m& \u001b[37mn\u001b[37mbs\u001b[37mp \u001b[37m; \u001b[37m( \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m) \u001b[37m& \u001b[37mn\u001b[37mbs\u001b[37mp \u001b[37m; \u001b[37mat\u001b[37mr \u001b[37m- \u001b[37mv \u001b[37m- \u001b[37mu\u001b[37mc\u001b[37mr \u001b[37m2 \u001b[37m/ \u001b[37m2 \u001b[37mlo\u001b[37mp\u001b[37md \u001b[37m[ \u001b[37mSE\u001b[37mP \u001b[37m] \u001b[37m[ \u001b[37mCL\u001b[37mS \u001b[37m] \u001b[37mnº \u001b[37mhistoria \u001b[37mc\u001b[37mlini\u001b[37mca \u001b[37m: \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37mnº\u001b[37mep\u001b[37miso\u001b[37mdi \u001b[37m: \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37msexe \u001b[37m: \u001b[37mdona \u001b[37mdata \u001b[37mde \u001b[37mnai\u001b[37mxement \u001b[37m: \u001b[37m22 \u001b[37m. \u001b[37m01 \u001b[37m. \u001b[37m1984 \u001b[37medat \u001b[37m: \u001b[37m35 \u001b[37manys \u001b[37mprocede\u001b[37mncia \u001b[37mdomi\u001b[37mcil \u001b[37m/ \u001b[37mres \u001b[37m. \u001b[37mso\u001b[37mc \u001b[37mservei \u001b[37mob\u001b[37mste\u001b[37mtrici\u001b[37ma \u001b[37mdata \u001b[37md \u001b[37m' \u001b[37ming\u001b[37mres \u001b[37m03 \u001b[37m. \u001b[37m10 \u001b[37m. \u001b[37m2019 \u001b[37mdata \u001b[37md \u001b[37m' \u001b[37malta \u001b[37m07 \u001b[37m. \u001b[37m10 \u001b[37m. \u001b[37m2019 \u001b[37m11 \u001b[37m: \u001b[37m59 \u001b[37m: \u001b[37m00 \u001b[37mat\u001b[37mes \u001b[37mper \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m, \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m; \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m, \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m; \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m, \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37m* \u001b[37minforme \u001b[37md \u001b[37m' \u001b[37malta \u001b[37md \u001b[37m' \u001b[37mhospital\u001b[37mitza\u001b[37mcio \u001b[37mmotiu \u001b[37md \u001b[37m' \u001b[37ming\u001b[37mres \u001b[37mmetro\u001b[37mrra\u001b[37mgia \u001b[37mante\u001b[37mcedent\u001b[37ms \u001b[31mno \u001b[37male\u001b[37mrgia\u001b[37ms \u001b[37mmed\u001b[37mica\u001b[37mmentos\u001b[37mas \u001b[37mconocidas \u001b[37m. \u001b[37minter\u001b[37mvenciones \u001b[37mqui\u001b[37mru\u001b[37mrgi\u001b[37mcas \u001b[37m: \u001b[37mmio\u001b[37mme\u001b[37mcto\u001b[37mmia \u001b[37mlap\u001b[37maros\u001b[37mco\u001b[37mpia \u001b[37m, \u001b[37mpoli\u001b[37mpect\u001b[37momia \u001b[37mante\u001b[37mcedent\u001b[37mes \u001b[37mpat\u001b[37mologic\u001b[37mos \u001b[37m: \u001b[37mno \u001b[37mrefiere \u001b[37mnie\u001b[37mga \u001b[37mhab\u001b[37mitos \u001b[37mto\u001b[37mxicos \u001b[37m. \u001b[37mno \u001b[37mmed\u001b[37mica\u001b[37mcion \u001b[37mhabitual \u001b[37m. \u001b[37mproces \u001b[37mactual \u001b[37medad \u001b[37m: \u001b[37m35 \u001b[37maños \u001b[37mt\u001b[37mpal \u001b[37m: \u001b[37m001\u001b[37m0 \u001b[37m( \u001b[37mge\u001b[37msta\u001b[37mcion \u001b[37me\u001b[37mcto\u001b[37mpica \u001b[37mtrata\u001b[37mda \u001b[37mcon \u001b[37mmet\u001b[37mot\u001b[37mre\u001b[37mxa\u001b[37mte \u001b[37m) \u001b[37mdur \u001b[37m: \u001b[37m28 \u001b[37m/ \u001b[37m5 \u001b[37m/ \u001b[37m2019 \u001b[37msg \u001b[37m: \u001b[37m18 \u001b[37m+ \u001b[37m2 \u001b[37mg\u001b[37msr\u001b[37mh \u001b[37m: \u001b[37mo \u001b[37m+ \u001b[37mge\u001b[37msta\u001b[37mcion \u001b[37mcontrol\u001b[37mada \u001b[37men \u001b[37malto \u001b[37mriesgo \u001b[37mob\u001b[37mste\u001b[37mtric\u001b[37mo \u001b[37m( \u001b[37mar\u001b[37mo \u001b[37m) \u001b[37mpor \u001b[37malto \u001b[37mriesgo \u001b[37mde \u001b[37mpre\u001b[37mec\u001b[37mlam\u001b[37mpsia \u001b[37men \u001b[37mprimer \u001b[37mtrim\u001b[37mestre \u001b[37m. \u001b[37macu\u001b[37mde \u001b[37mpor \u001b[37mmetro\u001b[37mrra\u001b[37mgia \u001b[37mes\u001b[37mcasa \u001b[37mde \u001b[37m4\u001b[37mh \u001b[37mde \u001b[37mevo\u001b[37mlu\u001b[37mcion \u001b[37m. \u001b[37mrefiere \u001b[37mdolor \u001b[37mab\u001b[37mdom\u001b[37minal \u001b[37mmas \u001b[37mac\u001b[37mentu\u001b[37mado \u001b[37ma \u001b[37mnivel \u001b[37mde \u001b[37mfos\u001b[37ma \u001b[37mili\u001b[37maca \u001b[37mizquierda \u001b[37m. \u001b[37mno \u001b[37msensa\u001b[37mcion \u001b[37mde \u001b[37mdina\u001b[37mmica \u001b[37mute\u001b[37mrina \u001b[37m. \u001b[37mno \u001b[37mhi\u001b[37mdro\u001b[37mrrea \u001b[37m. \u001b[37mrefiere \u001b[37msind\u001b[37mrome \u001b[37mmic\u001b[37mcional \u001b[37m. \u001b[37mno \u001b[37motra \u001b[37msin\u001b[37mtoma\u001b[37mtol\u001b[37mogia \u001b[37mde \u001b[37minteres \u001b[37m. \u001b[37mres\u001b[37mumen \u001b[37mge\u001b[37msta\u001b[37mcional \u001b[37m: \u001b[37mser\u001b[37mologia\u001b[37ms \u001b[37m: \u001b[37mnegativa\u001b[37ms \u001b[37m. \u001b[37mru\u001b[37mbe\u001b[37mola \u001b[37min\u001b[37mmune \u001b[37manal\u001b[37miti\u001b[37mca \u001b[37m: \u001b[37mh\u001b[37mb \u001b[37m: \u001b[37m10 \u001b[37m, \u001b[37m7 \u001b[37mh\u001b[37mt \u001b[37m: \u001b[37m32 \u001b[37m, \u001b[37m7 \u001b[37mplaque\u001b[37mtas \u001b[37m: \u001b[37m292\u001b[37m000 \u001b[37me\u001b[37mco \u001b[37m1\u001b[37mt \u001b[37m: \u001b[37mes \u001b[37mmodi\u001b[37mfica \u001b[37mfur \u001b[37m, \u001b[37mmarcador\u001b[37mes \u001b[37mnegativo\u001b[37ms \u001b[37m. \u001b[37mute\u001b[37mrina\u001b[37ms \u001b[37mnormale\u001b[37ms \u001b[37mtriple \u001b[37mscreening \u001b[37m: \u001b[37mbajo \u001b[37mriesgo \u001b[37m. \u001b[37mex\u001b[37mplo\u001b[37mrac\u001b[37mio \u001b[37mfisica \u001b[37mex\u001b[37mplo\u001b[37mrac\u001b[37mion \u001b[37men \u001b[37mur\u001b[37mgen\u001b[37mcias \u001b[37m: \u001b[37mta \u001b[37m109 \u001b[37m/ \u001b[37m70 \u001b[37mmm\u001b[37mh\u001b[37mg \u001b[37mf\u001b[37mc \u001b[37m71\u001b[37mx \u001b[37m' \u001b[37mt\u001b[37mª \u001b[37m36 \u001b[37m. \u001b[37m3º\u001b[37mc \u001b[37mex\u001b[37mpl \u001b[37m. \u001b[37mab\u001b[37mdom\u001b[37minal\n",
      "\u001b[37m-------------------True-------------------\n",
      "\u001b[37m-------------------Pred-------------------\n",
      " \u001b[31mesti\u001b[31mmula\u001b[31mcion \u001b[31mo\u001b[31mx\u001b[31mcito\u001b[31mcini\u001b[31mca \u001b[31m. \u001b[31mse \u001b[31mins\u001b[31mtau\u001b[31mra \u001b[31mane\u001b[31mstes\u001b[31mia \u001b[31mper\u001b[31midu\u001b[31mral \u001b[31m. \u001b[31mse \u001b[31mrealiza \u001b[31mprofil\u001b[31max\u001b[31mis \u001b[31manti\u001b[31mbio\u001b[31mtica \u001b[31mcon \u001b[31mpen\u001b[31mile\u001b[31mvel \u001b[31m5\u001b[31mm \u001b[31mu\u001b[31mi \u001b[31mdurante \u001b[31mam\u001b[31mnio\u001b[31mrre\u001b[31mxis \u001b[31m+ \u001b[31m2 \u001b[31m, \u001b[31m5 \u001b[31mm \u001b[31mu\u001b[31mi \u001b[31m/ \u001b[31m4\u001b[31mh \u001b[31mhasta \u001b[31mel \u001b[31mex\u001b[31mpuls\u001b[31mivo \u001b[31mpor \u001b[31msg\u001b[31mb \u001b[31mdes\u001b[31mcono\u001b[31mcido \u001b[31men \u001b[31mrpm \u001b[31mpret\u001b[31merm\u001b[31mino \u001b[31m. \u001b[31mpro\u001b[31mgres\u001b[31mion \u001b[31mad\u001b[31mecu\u001b[31mada \u001b[31mde \u001b[31mla \u001b[31mdil\u001b[31mata\u001b[31mcion \u001b[31mhasta \u001b[31mllegar \u001b[31ma \u001b[31mdil\u001b[31mata\u001b[31mcion \u001b[31mcompleta \u001b[31m. \u001b[31mel \u001b[31mdia \u001b[31m22 \u001b[31m/ \u001b[31m10 \u001b[31m/ \u001b[31m18 \u001b[31ma \u001b[31mlas \u001b[31m14 \u001b[31m: \u001b[31m15 \u001b[31mhoras \u001b[31m, \u001b[31mse \u001b[31masi\u001b[31mste \u001b[31mparte \u001b[31meut\u001b[31moci\u001b[31mco \u001b[31m, \u001b[31mobteniendo\u001b[31mse \u001b[31mre\u001b[31mcie\u001b[31mn \u001b[31mnacido \u001b[31mmujer \u001b[31m. \u001b[31mapa\u001b[31mgar \u001b[31m9 \u001b[31m/ \u001b[31m10 \u001b[31m. \u001b[31mpeso \u001b[31m243\u001b[31m0\u001b[31mg \u001b[31m. \u001b[31mph \u001b[31m7 \u001b[31m. \u001b[31m18 \u001b[31m/ \u001b[31m- \u001b[31m. \u001b[31mse \u001b[31mad\u001b[31mmini\u001b[31mstra \u001b[31mprofil\u001b[31max\u001b[31mis \u001b[31mo\u001b[31mcular \u001b[31mcon \u001b[31meri\u001b[31mtro\u001b[31mmic\u001b[31mina \u001b[31my \u001b[31mvitamina \u001b[31mk \u001b[31m. \u001b[31mal\u001b[31mum\u001b[31mbra\u001b[31mmiento \u001b[31mdirigido \u001b[31m. \u001b[31mplace\u001b[31mnta \u001b[31maparentemente \u001b[31mintegra \u001b[31m. \u001b[31mse \u001b[31mrev\u001b[31misa \u001b[31mcanal \u001b[31mbland\u001b[31mo \u001b[31mdel \u001b[31mparto \u001b[31m, \u001b[31mobjet\u001b[31miva\u001b[31mndose \u001b[31mem\u001b[31mdl \u001b[31my \u001b[31mdes\u001b[31mgar\u001b[31mro \u001b[31mpare\u001b[31md \u001b[31mva\u001b[31mginal \u001b[31mderecha \u001b[31mii \u001b[31m. \u001b[31mg\u001b[31msr\u001b[31mh \u001b[31m: \u001b[31m0 \u001b[31m- \u001b[31mru\u001b[31mbe\u001b[31mola \u001b[31min\u001b[31mmune \u001b[31m. \u001b[31mlac\u001b[31mtancia \u001b[31mmaterna \u001b[31m. \u001b[31mex\u001b[31mplo\u001b[31mrac\u001b[31mion \u001b[31mfisica \u001b[31mal \u001b[31malta \u001b[31mn\u001b[31mh\u001b[31mc \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m( \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m) \u001b[31mami \u001b[31m- \u001b[31mv \u001b[31m- \u001b[31mob\u001b[31ms \u001b[31m2 \u001b[31m/ \u001b[31m3 \u001b[31mlo\u001b[31mp\u001b[31md \u001b[31mdada \u001b[31mla \u001b[31mbuena \u001b[31mevo\u001b[31mlu\u001b[31mcion \u001b[31mdurante \u001b[31mel \u001b[31mpu\u001b[31mer\u001b[31mperi\u001b[31mo \u001b[31mse \u001b[31mdecide \u001b[31malta \u001b[31ma \u001b[31mdomi\u001b[31mcilio \u001b[31men \u001b[31mel \u001b[31mdia \u001b[31mde \u001b[31mhoy \u001b[31m. \u001b[31men \u001b[31mel \u001b[31mmomento \u001b[31mdel \u001b[31malta \u001b[31mla \u001b[31mpaciente \u001b[31mse \u001b[31mencuentra \u001b[31mcon \u001b[31mbuen \u001b[31mestado \u001b[31mgeneral \u001b[31m, \u001b[31mapi\u001b[31mreti\u001b[31mca \u001b[31m, \u001b[31mnor\u001b[31mmot\u001b[31mensa \u001b[31my \u001b[31mno \u001b[31mta\u001b[31mqui\u001b[31mcard\u001b[31mica \u001b[31m. \u001b[31mute\u001b[31mro \u001b[31mbien \u001b[31mcontra\u001b[31mido \u001b[31m, \u001b[31mcon \u001b[31mperd\u001b[31midas \u001b[31mva\u001b[31mginal\u001b[31mes \u001b[31mes\u001b[31mcasa\u001b[31ms \u001b[31m. \u001b[31mrealiza \u001b[31mlac\u001b[31mtancia \u001b[31mmaterna \u001b[31m. \u001b[31mori\u001b[31menta\u001b[31mcio \u001b[31mdiagnostic\u001b[31ma \u001b[31mtrabajo \u001b[31mde \u001b[31mparto \u001b[31mparto \u001b[31meut\u001b[31moci\u001b[31mco \u001b[31mepi\u001b[31msio\u001b[31mtomia \u001b[31mml\u001b[31md \u001b[31m+ \u001b[31mdes\u001b[31mgar\u001b[31mro \u001b[31mde \u001b[31m2º \u001b[31mgrado \u001b[31mpu\u001b[31mer\u001b[31mperi\u001b[31mo \u001b[31mpro\u001b[31mced\u001b[31miments \u001b[31masistencia \u001b[31mal \u001b[31mtrabajo \u001b[31mde \u001b[31mparto \u001b[31m( \u001b[31mven\u001b[31moc\u001b[31mlisi\u001b[31ms \u001b[31m, \u001b[31mcontrol \u001b[31mde \u001b[31mconstantes \u001b[31m, \u001b[31mns\u001b[31mt \u001b[31m, \u001b[31mane\u001b[31mstes\u001b[31mia \u001b[31mepi\u001b[31mdura\u001b[31ml \u001b[31m) \u001b[31m. \u001b[31masistencia \u001b[31mal \u001b[31mparto \u001b[31mrevision \u001b[31mdel \u001b[31mcanal \u001b[31mbland\u001b[31mo \u001b[31mdel \u001b[31mparto \u001b[31msut\u001b[31mura \u001b[31mde \u001b[31mepi\u001b[31msio\u001b[31mtomia \u001b[31my \u001b[31mdes\u001b[31mgar\u001b[31mro \u001b[31manal\u001b[31mgesi\u001b[31ma \u001b[31my \u001b[31mane\u001b[31mstes\u001b[31mia \u001b[31mepi\u001b[31mdura\u001b[31ml \u001b[31msue\u001b[31mrot\u001b[31mera\u001b[31mpia \u001b[31manal\u001b[31miti\u001b[31mcas \u001b[31mg\u001b[31msr\u001b[31mh \u001b[31mtractament \u001b[31mi \u001b[31mre\u001b[31mcoma\u001b[31mnac\u001b[31mions \u001b[31ma \u001b[31ml \u001b[31m' \u001b[31malta \u001b[31mhierro \u001b[31m1 \u001b[31mcom\u001b[31mpri\u001b[31mmido \u001b[31mcada \u001b[31m24\u001b[31mh \u001b[31men \u001b[31may\u001b[31munas \u001b[31m( \u001b[31ming\u001b[31merir \u001b[31mcon \u001b[31mzum\u001b[31mo \u001b[31mde \u001b[31mnar\u001b[31manja \u001b[31mu \u001b[31motro \u001b[31malimento \u001b[31macido \u001b[31m) \u001b[31m. \u001b[31macido \u001b[31mf\u001b[31moli\u001b[31mco \u001b[31m1 \u001b[31mcom\u001b[31mpri\u001b[31mmido \u001b[31mcada \u001b[31m24\u001b[31mh \u001b[31mal \u001b[31mmedio \u001b[31mdia \u001b[31mmientras \u001b[31mdure \u001b[31mlac\u001b[31mtancia \u001b[31m. \u001b[31msi \u001b[31mpresenta \u001b[31mdolor \u001b[31mpuede \u001b[31mtomar \u001b[31mpara\u001b[31mcet\u001b[31mamo\u001b[31ml \u001b[31m1\u001b[31mcom\u001b[31mpri\u001b[31mmido \u001b[31m/ \u001b[31m8\u001b[31mh \u001b[31m. \u001b[31mcontrol \u001b[31mcontrol \u001b[31mde \u001b[31msu \u001b[31mpat\u001b[31mologia \u001b[31mde \u001b[31mbase \u001b[31m( \u001b[31mas\u001b[31mma \u001b[31m) \u001b[31msegun \u001b[31mcontrole\u001b[31ms \u001b[31mhabitual\u001b[31mes \u001b[31msi \u001b[31mpresenta \u001b[31mgr\u001b[31miet\u001b[31mas \u001b[31men \u001b[31mpez\u001b[31mones \u001b[31m* \u001b[31m* \u001b[31m& \u001b[31mn\u001b[31mbs\u001b[31mp \u001b[31m; \u001b[31m( \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m) \u001b[31m& \u001b[31mn\u001b[31mbs\u001b[31mp \u001b[31m; \u001b[31mat\u001b[31mr \u001b[31m- \u001b[31mv \u001b[31m- \u001b[31mu\u001b[31mc\u001b[31mr \u001b[31m2 \u001b[31m/ \u001b[31m2 \u001b[31mlo\u001b[31mp\u001b[31md \u001b[31m[ \u001b[31mSE\u001b[31mP \u001b[31m] \u001b[31m[ \u001b[31mCL\u001b[31mS \u001b[31m] \u001b[31mnº \u001b[31mhistoria \u001b[31mc\u001b[31mlini\u001b[31mca \u001b[31m: \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31mnº\u001b[31mep\u001b[31miso\u001b[31mdi \u001b[31m: \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31msexe \u001b[31m: \u001b[31mdona \u001b[31mdata \u001b[31mde \u001b[31mnai\u001b[31mxement \u001b[31m: \u001b[31m22 \u001b[31m. \u001b[31m01 \u001b[31m. \u001b[31m1984 \u001b[31medat \u001b[31m: \u001b[31m35 \u001b[31manys \u001b[31mprocede\u001b[31mncia \u001b[31mdomi\u001b[31mcil \u001b[31m/ \u001b[31mres \u001b[31m. \u001b[31mso\u001b[31mc \u001b[31mservei \u001b[31mob\u001b[31mste\u001b[31mtrici\u001b[31ma \u001b[31mdata \u001b[31md \u001b[31m' \u001b[31ming\u001b[31mres \u001b[31m03 \u001b[31m. \u001b[31m10 \u001b[31m. \u001b[31m2019 \u001b[31mdata \u001b[31md \u001b[31m' \u001b[31malta \u001b[31m07 \u001b[31m. \u001b[31m10 \u001b[31m. \u001b[31m2019 \u001b[31m11 \u001b[31m: \u001b[31m59 \u001b[31m: \u001b[31m00 \u001b[31mat\u001b[31mes \u001b[31mper \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m, \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m; \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m, \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m; \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m, \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31m* \u001b[31minforme \u001b[31md \u001b[31m' \u001b[31malta \u001b[31md \u001b[31m' \u001b[31mhospital\u001b[31mitza\u001b[31mcio \u001b[31mmotiu \u001b[31md \u001b[31m' \u001b[31ming\u001b[31mres \u001b[31mmetro\u001b[31mrra\u001b[31mgia \u001b[31mante\u001b[31mcedent\u001b[31ms \u001b[31mno \u001b[31male\u001b[31mrgia\u001b[31ms \u001b[31mmed\u001b[31mica\u001b[31mmentos\u001b[31mas \u001b[31mconocidas \u001b[31m. \u001b[31minter\u001b[31mvenciones \u001b[31mqui\u001b[31mru\u001b[31mrgi\u001b[31mcas \u001b[31m: \u001b[31mmio\u001b[31mme\u001b[31mcto\u001b[31mmia \u001b[31mlap\u001b[31maros\u001b[31mco\u001b[31mpia \u001b[31m, \u001b[31mpoli\u001b[31mpect\u001b[31momia \u001b[31mante\u001b[31mcedent\u001b[31mes \u001b[31mpat\u001b[31mologic\u001b[31mos \u001b[31m: \u001b[31mno \u001b[31mrefiere \u001b[31mnie\u001b[31mga \u001b[31mhab\u001b[31mitos \u001b[31mto\u001b[31mxicos \u001b[31m. \u001b[31mno \u001b[31mmed\u001b[31mica\u001b[31mcion \u001b[31mhabitual \u001b[31m. \u001b[31mproces \u001b[31mactual \u001b[31medad \u001b[31m: \u001b[31m35 \u001b[31maños \u001b[31mt\u001b[31mpal \u001b[31m: \u001b[31m001\u001b[31m0 \u001b[31m( \u001b[31mge\u001b[31msta\u001b[31mcion \u001b[31me\u001b[31mcto\u001b[31mpica \u001b[31mtrata\u001b[31mda \u001b[31mcon \u001b[31mmet\u001b[31mot\u001b[31mre\u001b[31mxa\u001b[31mte \u001b[31m) \u001b[31mdur \u001b[31m: \u001b[31m28 \u001b[31m/ \u001b[31m5 \u001b[31m/ \u001b[31m2019 \u001b[31msg \u001b[31m: \u001b[31m18 \u001b[31m+ \u001b[31m2 \u001b[31mg\u001b[31msr\u001b[31mh \u001b[31m: \u001b[31mo \u001b[31m+ \u001b[31mge\u001b[31msta\u001b[31mcion \u001b[31mcontrol\u001b[31mada \u001b[31men \u001b[31malto \u001b[31mriesgo \u001b[31mob\u001b[31mste\u001b[31mtric\u001b[31mo \u001b[31m( \u001b[31mar\u001b[31mo \u001b[31m) \u001b[31mpor \u001b[31malto \u001b[31mriesgo \u001b[31mde \u001b[31mpre\u001b[31mec\u001b[31mlam\u001b[31mpsia \u001b[31men \u001b[31mprimer \u001b[31mtrim\u001b[31mestre \u001b[31m. \u001b[31macu\u001b[31mde \u001b[31mpor \u001b[31mmetro\u001b[31mrra\u001b[31mgia \u001b[31mes\u001b[31mcasa \u001b[31mde \u001b[31m4\u001b[31mh \u001b[31mde \u001b[31mevo\u001b[31mlu\u001b[31mcion \u001b[31m. \u001b[31mrefiere \u001b[31mdolor \u001b[31mab\u001b[31mdom\u001b[31minal \u001b[31mmas \u001b[31mac\u001b[31mentu\u001b[31mado \u001b[31ma \u001b[31mnivel \u001b[31mde \u001b[31mfos\u001b[31ma \u001b[31mili\u001b[31maca \u001b[31mizquierda \u001b[31m. \u001b[31mno \u001b[31msensa\u001b[31mcion \u001b[31mde \u001b[31mdina\u001b[31mmica \u001b[31mute\u001b[31mrina \u001b[31m. \u001b[31mno \u001b[31mhi\u001b[31mdro\u001b[31mrrea \u001b[31m. \u001b[31mrefiere \u001b[31msind\u001b[31mrome \u001b[31mmic\u001b[31mcional \u001b[31m. \u001b[31mno \u001b[31motra \u001b[31msin\u001b[31mtoma\u001b[31mtol\u001b[31mogia \u001b[31mde \u001b[31minteres \u001b[31m. \u001b[31mres\u001b[31mumen \u001b[31mge\u001b[31msta\u001b[31mcional \u001b[31m: \u001b[31mser\u001b[31mologia\u001b[31ms \u001b[31m: \u001b[31mnegativa\u001b[31ms \u001b[31m. \u001b[31mru\u001b[31mbe\u001b[31mola \u001b[31min\u001b[31mmune \u001b[31manal\u001b[31miti\u001b[31mca \u001b[31m: \u001b[31mh\u001b[31mb \u001b[31m: \u001b[31m10 \u001b[31m, \u001b[31m7 \u001b[31mh\u001b[31mt \u001b[31m: \u001b[31m32 \u001b[31m, \u001b[31m7 \u001b[31mplaque\u001b[31mtas \u001b[31m: \u001b[31m292\u001b[31m000 \u001b[31me\u001b[31mco \u001b[31m1\u001b[31mt \u001b[31m: \u001b[31mes \u001b[31mmodi\u001b[31mfica \u001b[31mfur \u001b[31m, \u001b[31mmarcador\u001b[31mes \u001b[31mnegativo\u001b[31ms \u001b[31m. \u001b[31mute\u001b[31mrina\u001b[31ms \u001b[31mnormale\u001b[31ms \u001b[31mtriple \u001b[31mscreening \u001b[31m: \u001b[31mbajo \u001b[31mriesgo \u001b[31m. \u001b[31mex\u001b[31mplo\u001b[31mrac\u001b[31mio \u001b[31mfisica \u001b[31mex\u001b[31mplo\u001b[31mrac\u001b[31mion \u001b[31men \u001b[31mur\u001b[31mgen\u001b[31mcias \u001b[31m: \u001b[31mta \u001b[31m109 \u001b[31m/ \u001b[31m70 \u001b[31mmm\u001b[31mh\u001b[31mg \u001b[31mf\u001b[31mc \u001b[31m71\u001b[31mx \u001b[31m' \u001b[31mt\u001b[31mª \u001b[31m36 \u001b[31m. \u001b[31m3º\u001b[31mc \u001b[31mex\u001b[31mpl \u001b[31m. \u001b[31mab\u001b[31mdom\u001b[31minal\n",
      "\u001b[37m-------------------Pred-------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[119], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43meval\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbert_tagger\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mtag_pad_idx\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[118], line 15\u001b[0m, in \u001b[0;36meval\u001b[0;34m(model, dataloader, n_batches, tag_pad_idx)\u001b[0m\n\u001b[1;32m     13\u001b[0m tags \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     14\u001b[0m tokens_txt \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx_ref\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 15\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m predictions \u001b[38;5;241m=\u001b[39m predictions\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, predictions\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;66;03m#merge sent len and batch dimensions\u001b[39;00m\n\u001b[1;32m     17\u001b[0m predictions \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(predictions,axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[13], line 21\u001b[0m, in \u001b[0;36mBERT_Tagger.forward\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, tokens):\n\u001b[0;32m---> 21\u001b[0m     bert_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlast_hidden_state\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     23\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(bert_out)\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m predictions\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:1020\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1011\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m   1013\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(\n\u001b[1;32m   1014\u001b[0m     input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[1;32m   1015\u001b[0m     position_ids\u001b[39m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1018\u001b[0m     past_key_values_length\u001b[39m=\u001b[39mpast_key_values_length,\n\u001b[1;32m   1019\u001b[0m )\n\u001b[0;32m-> 1020\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[1;32m   1021\u001b[0m     embedding_output,\n\u001b[1;32m   1022\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[1;32m   1023\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   1024\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m   1025\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[1;32m   1026\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m   1027\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   1028\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1029\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1030\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1031\u001b[0m )\n\u001b[1;32m   1032\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1033\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(sequence_output) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:610\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    601\u001b[0m     layer_outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[1;32m    602\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m    603\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    607\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    608\u001b[0m     )\n\u001b[1;32m    609\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 610\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[1;32m    611\u001b[0m         hidden_states,\n\u001b[1;32m    612\u001b[0m         attention_mask,\n\u001b[1;32m    613\u001b[0m         layer_head_mask,\n\u001b[1;32m    614\u001b[0m         encoder_hidden_states,\n\u001b[1;32m    615\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    616\u001b[0m         past_key_value,\n\u001b[1;32m    617\u001b[0m         output_attentions,\n\u001b[1;32m    618\u001b[0m     )\n\u001b[1;32m    620\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    621\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:495\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    483\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    484\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    485\u001b[0m     hidden_states: torch\u001b[39m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    492\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[torch\u001b[39m.\u001b[39mTensor]:\n\u001b[1;32m    493\u001b[0m     \u001b[39m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m    494\u001b[0m     self_attn_past_key_value \u001b[39m=\u001b[39m past_key_value[:\u001b[39m2\u001b[39m] \u001b[39mif\u001b[39;00m past_key_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 495\u001b[0m     self_attention_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention(\n\u001b[1;32m    496\u001b[0m         hidden_states,\n\u001b[1;32m    497\u001b[0m         attention_mask,\n\u001b[1;32m    498\u001b[0m         head_mask,\n\u001b[1;32m    499\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    500\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mself_attn_past_key_value,\n\u001b[1;32m    501\u001b[0m     )\n\u001b[1;32m    502\u001b[0m     attention_output \u001b[39m=\u001b[39m self_attention_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    504\u001b[0m     \u001b[39m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:425\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    416\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    417\u001b[0m     hidden_states: torch\u001b[39m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    423\u001b[0m     output_attentions: Optional[\u001b[39mbool\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    424\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[torch\u001b[39m.\u001b[39mTensor]:\n\u001b[0;32m--> 425\u001b[0m     self_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mself(\n\u001b[1;32m    426\u001b[0m         hidden_states,\n\u001b[1;32m    427\u001b[0m         attention_mask,\n\u001b[1;32m    428\u001b[0m         head_mask,\n\u001b[1;32m    429\u001b[0m         encoder_hidden_states,\n\u001b[1;32m    430\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    431\u001b[0m         past_key_value,\n\u001b[1;32m    432\u001b[0m         output_attentions,\n\u001b[1;32m    433\u001b[0m     )\n\u001b[1;32m    434\u001b[0m     attention_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput(self_outputs[\u001b[39m0\u001b[39m], hidden_states)\n\u001b[1;32m    435\u001b[0m     outputs \u001b[39m=\u001b[39m (attention_output,) \u001b[39m+\u001b[39m self_outputs[\u001b[39m1\u001b[39m:]  \u001b[39m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:357\u001b[0m, in \u001b[0;36mBertSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    353\u001b[0m attention_probs \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39msoftmax(attention_scores, dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    355\u001b[0m \u001b[39m# This is actually dropping out entire tokens to attend to, which might\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[39m# seem a bit unusual, but is taken from the original Transformer paper.\u001b[39;00m\n\u001b[0;32m--> 357\u001b[0m attention_probs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout(attention_probs)\n\u001b[1;32m    359\u001b[0m \u001b[39m# Mask heads if we want to\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \u001b[39mif\u001b[39;00m head_mask \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.10/site-packages/torch/nn/modules/dropout.py:59\u001b[0m, in \u001b[0;36mDropout.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mdropout(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mp, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minplace)\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.10/site-packages/torch/nn/functional.py:1252\u001b[0m, in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1250\u001b[0m \u001b[39mif\u001b[39;00m p \u001b[39m<\u001b[39m \u001b[39m0.0\u001b[39m \u001b[39mor\u001b[39;00m p \u001b[39m>\u001b[39m \u001b[39m1.0\u001b[39m:\n\u001b[1;32m   1251\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mdropout probability has to be between 0 and 1, \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbut got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(p))\n\u001b[0;32m-> 1252\u001b[0m \u001b[39mreturn\u001b[39;00m _VF\u001b[39m.\u001b[39mdropout_(\u001b[39minput\u001b[39m, p, training) \u001b[39mif\u001b[39;00m inplace \u001b[39melse\u001b[39;00m _VF\u001b[39m.\u001b[39;49mdropout(\u001b[39minput\u001b[39;49m, p, training)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "eval(bert_tagger,train_loader,20,tag_pad_idx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 ('ML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "da600ade1a771c82ddf6d22a5a41f856afbf3528a3611e1c80e3ac6da17c9450"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
